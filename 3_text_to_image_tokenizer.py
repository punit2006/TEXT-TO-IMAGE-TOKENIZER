# -*- coding: utf-8 -*-
"""3. TEXT-TO-IMAGE-TOKENIZER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_yoWpTLAobjjC3Wyz5Dgq8X3o4pLjHg9
"""

!pip install transformers torch

from huggingface_hub import notebook_login

# Log in to Hugging Face Hub
notebook_login()

from transformers import AutoTokenizer, AutoModel
import torch

# Load the pre-trained model and tokenizer
model_name = 'bert-base-uncased'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# Define the text preprocessing function
def preprocess_text(text_descriptions):
    # Tokenize the text descriptions
    inputs = tokenizer(text_descriptions, return_tensors='pt', padding=True, truncation=True, max_length=512)

    # Generate embeddings
    with torch.no_grad():
        outputs = model(**inputs)

    # Use the embeddings from the last hidden states
    embeddings = outputs.last_hidden_state.mean(dim=1)

    return embeddings

# Example usage
text_descriptions = [
    "A beautiful sunset over the mountains.",
    "A bustling city street filled with people.",
    "A quiet forest with a clear blue sky."
]

embeddings = preprocess_text(text_descriptions)
print(embeddings.shape)  # Should print the shape of the embeddings tensor

# Placeholder for text-to-image model integration
def generate_image_from_embeddings(embeddings):
    # Placeholder for text-to-image model logic
    # This function will take embeddings and generate an image
    pass

# Generate images from the embeddings
images = generate_image_from_embeddings(embeddings)

from sklearn.metrics.pairwise import cosine_similarity

# Assuming `embeddings` is your tensor of shape [3, 768]
embeddings_array = embeddings.detach().numpy()

# Compute cosine similarity
similarity_matrix = cosine_similarity(embeddings_array)

print("Cosine Similarity Matrix:")
print(similarity_matrix)

!pip install diffusers transformers scipy torch

from diffusers import StableDiffusionPipeline
import torch

# Load the Stable Diffusion model
model_id = "CompVis/stable-diffusion-v1-4"
pipe = StableDiffusionPipeline.from_pretrained(model_id)
pipe = pipe.to("cuda")  # Use GPU if available

def generate_image_from_text(prompts):
    images = []
    for prompt in prompts:
        # Generate an image for each prompt
        image = pipe(prompt).images[0]
        images.append(image)
    return images

# Example usage
prompts = [
    "A serene lakeside cabin surrounded by autumn foliage.",
    "A futuristic cityscape at night with neon lights and flying cars.",
    "A cozy bookstore caf√© with wooden shelves filled with books and a warm fireplace."
]

images = generate_image_from_text(prompts)

display(images)

from PIL import Image

def save_images(images, filenames):
    for image, filename in zip(images, filenames):
        image.save(filename)

# Example usage
filenames = ["image1.png", "image2.png", "image3.png"]
save_images(images, filenames)

